# Arxiv Harverster

This program is dedicated to automatically harvesting the Arxiv.org website for new and recent papers and filtering them out by the relevant key words.
## Arxiv-Harvester

This applicaiton works based on the following principle:

1. Check out which website you would like to visit (web crawling).
2. Save the response of your request in the file.

After opening the file, you can work with it locally after saving a response text if you wish.

It would be useful to employ regular expressions, as the website response is a text (.txt) file.

A recent alternative to this approach is based on a  BeautifulSoup package which can give "pretty" outputs from the HTML responses. This project has two alternative versions/codes - one using only requests and regular expressions, and another using in addition Beaitiful Soup. 

Chose any and let's start harvesting!

Run as

```
python ArxivHarvester.py
```

If you are doing research/science and tired/lazy of manually going through arxiv every day, this program might be just right for you.

--------------------------

I wrote a recent edition / alternative approach to the same task using a BeatifulSoup. 
It works in the same way as the previous ArxivHarvester, just easier to find and retrieve a relevant information from a website on a backend.

Run as

```
python Beautiful_Soup_Harvester.py
```

If you have any questions, comments, found an error, or would simply like to connect and say "Hi!", my contacts are below.

## Contacts

[LinkedIn](https://www.linkedin.com/in/ruslan-brilenkov/)
